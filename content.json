{"meta":{"title":"Blog","subtitle":"Blog","description":"略懂设计的程序员","author":"佐伯楽","url":"https://saekiraku.github.io"},"pages":[{"title":"关于我","date":"2018-05-17T05:58:23.000Z","updated":"2018-05-18T03:26:24.000Z","comments":true,"path":"about/index.html","permalink":"https://saekiraku.github.io/about/index.html","excerpt":"","text":"—— 2018-05-18 姓名：郭奇奇性别：男生日：1996-02-28 职业技能技术栈：UI、产品、C4D、Flash、ActionScript、HTML5、NodeJS、ThinkPHP、MySQL、SQLite、MongoDB、Docker、Python、易语言 学习经历大概就是3年级接触Flash，6年级接触编程。至今12年 Flash 经验、10年 ActionScript 开发经验、3年易语言（初高中用过后，做过几次外包，之后就不在用了）、4年前端开发及架构经验、2年PHP开发经验、1年Docker、Redis 集群、Linux运维经验。4年UI设计、产品经验。 大学选的Java专业，但是觉得Java Web没前途而自学前端，虽然没跟着老师学过Java，但是由于比较简单还是很轻松毕业了，另外再开Java课程之前，曾自学2星期后参与比赛获得了华北赛区第二名。有基于Java的Android开发经验，不过个人更喜欢Cordova、Electron这样的跨平台开发技术栈。 比较喜欢新技术，GraphQL、Meteor.js、Flutter、C4D基本都有过研究。其他的人生经历太过复杂，就不多说了。 兴趣爱好诗、美术、书法、音乐、摄影 绘画作品 书法作品 摄影作品 C4D作品 其他"}],"posts":[{"title":"【译】MacOS下的交叉编译","slug":"【译】MacOS下的交叉编译","date":"2018-09-08T12:09:52.000Z","updated":"2018-09-08T15:15:37.446Z","comments":true,"path":"article/18577/","link":"","permalink":"https://saekiraku.github.io/article/18577/","excerpt":"原文地址：Easy Windows and Linux cross-compilers for MacOS","text":"原文地址：Easy Windows and Linux cross-compilers for MacOS 本文章基于以下CC协议进行知识共享：署名（BY）-非商业性使用（NC）-禁止演绎（ND） 在 MacOS 下编译 Linux 和 Windows 的可执行程序，需要使用 Homebrew 安装 C/C++ 交叉编译工具链： 12brew install FiloSottile/musl-cross/musl-crossbrew install mingw-w64 交叉编译 C 和 C++ 是非常痛苦的。 当你使用 Golang 时，你只需要设置一个环境变量即可（译注：CC），对于 C 你则需要一整套离散的工具链，这也许需要一些中间件来进行构建，并且你需要非常清楚你每一步的目的。 musl-cross-make幸运的是，Rich Felker 设计了一套 Makefile 来构建基于 musl 库的交叉编译器 —— musl-cross-make。它使用了一些补丁，使其在 MacOS 上可以良好的运行。 musl-cross-make 完美实现了独立的交叉编译器，所以你无需关注正确的库路径，也不需要了解在何处存放工具链。同时，它可以编译到任意架构的目标 Linux 上。 需要注意的是，它是基于 musl 的 C 标准库。这意味着编译后的二进制库文件只能运行在基于 musl 的系统上，例如：Alpine。即便如此，如果你通过传入 --static 参数来构建静态二进制文件便可以运行在任何系统上，包括 scratch Docker 容器中。musl 是一个特殊的工程，它可以完整的支持静态编译二进制文件（译注：跨平台），所以并不推荐使用 glibc 来编译。 homebrew-musl-cross到目前为止，我非常喜欢 Homebrew。它允许你在一个完美的沙盒中构建应用，并且只有可执行文件链接到了环境变量中，类似 GNU Stow 的风格。同时，它也能管理资源并提供非常强大的开发工具。 所以，我将 musl-cross-make 封装成了一个 Homebrew Formula 。我花了很长时间来构建这个项目，但是最终它成为了一个完整的交叉编译工具链，并且以不同的前缀链接进了 /usr/local/bin。例如： x86_64-linux-musl-gcc 。 1brew install FiloSottile/musl-cross/musl-cross 它包含了一个预编译过的 Homebrew Bottle ，可以运行在 High Sierra 系统中。所以如果你想自己通过源码构建，使用 brew install --build-from-source 即可、 其他的架构也是被支持的。比如基于树莓派的交叉编译器： 1brew install FiloSottile/musl-cross/musl-cross --without-x86_64 --with-arm-hf 你也可以使用 --with-i486（x86 32-bit），--with-aarch64（ARM 64-bit），--with-arm（ARM soft-float）和 --with-mips 等开关参数。 应用到 Golang 和 Rust为了交叉编译基于 cgo 的项目，你可以设置 CC 和 CCX 环境变量标志来构建到 x86_64-linux-musl-gcc 和 x86_64-linux-musl-g++（或其他相关架构）。该环境变量标志应放在 GOOS 和 GOARCH 两个环境变量标志之前。 12CC=x86_64-linux-musl-gcc GOOS=linux GOARCH=amd64 CGO_ENABLED=1 go build -a -v main.go// 译注：自己额外增加的范例 如果使用这个工具链来交叉编译 Rust 项目，则添加以下设置到 .cargo/config： 12[target.x86_64-unknown-linux-musl]linker = &quot;x86_64-linux-musl-gcc&quot; 这里有一份更完整的 Rust 交叉编译教程：Cross compile and link a static binary on macos for linux with cargo and rust mingw-w64对于 Windows 系统下的交叉编译，有一个 Mingw-w64 的 Formula 在 homebrew-core 中，所以你可以使用 brew install mingw-w64 直接安装。 这个 GCC 工具链的前缀为 x86_64-w64-mingw32- 和 i686-w64-mingw32-。 如果你觉得交叉编译比你想象中的有趣，也许你会想关注我的 Twitter 译后记第一次在 Golang 项目中使用到了一个基于 CGO 的库 —— go-sqlite3，并且交叉编译失败，在查找解决方案时发现了一篇不错的文章，因此而翻译。这篇文章不错的地方一是包含了实际问题的解决方案；二是原文作者的讲解十分清晰，翻译起来也十分轻松；三是在原作者在解决问题的基础上，又能简单讲解交叉编译的一些基础知识，对于交叉编译后续的深入研究，可以作为不错的切入点。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://saekiraku.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://saekiraku.github.io/tags/Linux/"}]},{"title":"启嘉网微服务架构实践","slug":"启嘉网微服务架构实践","date":"2018-07-31T02:20:53.000Z","updated":"2018-08-06T00:38:19.201Z","comments":true,"path":"article/20538/","link":"","permalink":"https://saekiraku.github.io/article/20538/","excerpt":"关于微服务架构的思考、设计和实践","text":"关于微服务架构的思考、设计和实践 本文章基于以下CC协议进行知识共享：署名（BY）-非商业性使用（NC）-禁止演绎（ND） 为什么选择微服务在之前的启嘉网后端中，我们使用传统的单体架构 .Net + PHP (中间层) 进行开发。但是在实际的开发过程中，遇到了以下几点问题： 功能模块越来越多的时候，项目维护越来越困难，在推送版本更新时，经常出现未知问题导致整站崩溃。 一些高负载的功能模块无法抽离，导致负载均衡较难实施。 无意识写出的高耦合代码，导致产品需求变更时，连带修改太多。 开发人员出现变动时（如请假、离职），较难调整开发安排及排期。 而使用微服务架构的话，各个功能模块（服务）可以单独部署、单独更新，即便出现问题，也可以保证其他模块的正常使用。同时，也可以将高负载的微服务抽离到性能更高的服务器上进行优化。其次，微服务的设计思想所带来的低耦合，对产品设计、开发都比较有利。最后，在后端人员出现变动时，可以随时抽离人数更多的前端人员，使用 NodeJS / Python / Golang 等任意一种语言开发微服务，来保证排期的正常进行。 架构设计概述 如上图所示，微服务部分主要分为 3 层 —— 网关层、服务发现层、应用层。 网关层客户端请求（浏览器）首先经过 负载均衡服务器（用于提升网关层的并发能力）。由 网关层 分析请求所涉及的微服务，然后调用 服务发现层 的接口，判断服务存活状态，并对多实例的微服务进行负载均衡。获取到微服务实例的地址后，进行 RPC 远程调用，然后将结果返回给客户端。 应用层应用层即实际的业务逻辑部分，由基于 NodeJS / Pytonn / Golang 等任意框架或语言开发的微服务组成。服务间通信使用谷歌的 gRPC 框架进行远程调用。应用层的服务在启动时会调用 服务发现层 的接口进行服务注册，同时，在服务不可用时，服务发现层 会自动剔除该节点来保证服务的稳定运行。虽然说以启嘉网目前的规模，使用 RPC 还是 HTTP 并不会产生较大的性能差异，但是为了适配未来的发展和学习研究等目的，我们仍然选择了 gRPC。 服务发现层网上主流的解决方案中，通常是使用 gRPC + etcd 这样的组合，并由 etcd 进行服务注册与发现的工作。但是由于时间关系，在方案落地过程中，我没有太多的时间去完全学习所有的技术栈组合。因此决定使用自己擅长的 NodeJS 自行开发，同时由于 JS 是动态语言，那么在构建 服务发现层 和 网关层 这样不确定（动态）因素较多的应用时，不必像 Golang 一样频繁的使用反射来实现相关功能。 落地实施在启嘉网这边落地微服务有几个原则： 不让架构过分入侵业务代码。 优先使用类库而不是框架。 渐进式。 为了实现以上几点，我们针对 NodeJS / Python / Goloang 封装了基础库，将服务发现层的相关操作对外简化，来达到 不让架构过分入侵业务代码，如 Golang 建立服务的所有操作仅需要4行代码，其中包括检测服务器自身环境、自动寻找可用地址和端口等等。 123456func main() &#123; server := microservice.CreateServer() service := new(service) pb.RegisterGreeterServer(server, service) microservice.Register(\"helloworld\", server)&#125; 优先使用类库而不是框架 实际也是一个不入侵业务代码的体现，但是更重要的是希望能简化处理，不要因为使用某个框架而学习框架带来的很多抽象概念。 最后，由于项目功能模块比较多，想快速完美的切换到微服务架构是基本不可能的。因此，需要 渐进式，用细分化的微服务逐渐替换掉原有单体应用中的功能。这部分只需要网关层判断一下即可。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://saekiraku.github.io/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://saekiraku.github.io/tags/微服务/"}]},{"title":"Linux 基本安全策略","slug":"Linux 基本安全策略","date":"2018-07-11T08:07:40.000Z","updated":"2018-07-23T04:03:54.200Z","comments":true,"path":"article/21343/","link":"","permalink":"https://saekiraku.github.io/article/21343/","excerpt":"在真实经历过“删库跑路”事件后，吸取教训、反思总结的一套服务器安全策略。","text":"在真实经历过“删库跑路”事件后，吸取教训、反思总结的一套服务器安全策略。 本文章基于以下CC协议进行知识共享：署名（BY）-非商业性使用（NC）-禁止演绎（ND） 1. 用户与用户组涉及命令：useradd, groupadd, userdel, groupdel, passwd （点击命令可以查看帮助手册） 通过用户及用户组的管理和分配，可以很方便的针对不同目录、文件、程序进行读写及运行限制。 因为让所有管理员直接登录 root 进行管理是非常危险的操作 。通过用户（组）管理，我们可以做到：只允许 somebody 用户访问 /home，或者允许整个 admin 用户组的用户访问 /home。 用户组管理12345678# 新建 admin 用户组groupadd admin# 新建 test 用户组并指定 IDgroupadd -g 666 admin# 删除 test 用户组groupdel test 用户管理12345678910111213# 新建 test 用户useradd test# 新建 somebody 用户并进行设置user -c \"某用户\" -d /home -g admin -M -n# -c : 备注# -d : 登入时的初始目录# -g : 所属用户组# -M : 不要自动建立用户的登入目录# -n : 取消建立以用户名称为名的群组# 为 somebody 用户设置密码passwd somebody 注意：手动设定用户ID值时要尽量要大于500，以免冲突。因为Linux安装后会建立一些特殊用户，一般0到499之间的值留给bin、mail这样的系统账号。 查看系统中已有的用户和用户组12cat /etc/passwdcat /etc/group 2. 禁止 root 账号直接登录涉及命令：vim, service 完成上述操作后，我们就可以配置 ssh 来禁止 root 直接登录了。因为 root 是所有 Linux 系统的默认超管账号，所以很容易进行穷举密码。更安全的方法是通过创建的账号登录到服务器后，使用 su 命令来认证到 root 账号。 在登录方面，也可以配置公钥或私钥认证来进行登录，一是可以免去每次登陆都要输密码的麻烦，二是避免在现实世界中输入密码被有心人看到并记下，三是加大穷举破解的难度。 12345678# 编辑 sshd 配置文件vim /etc/ssh/sshd_config# 按下 ESC 键输入 /PermitRootLogin 进行搜索（vim技巧）# 将 PermitRootLogin 的值改为 no 然后保存文件# 重启 sshd 服务service sshd restart 3. 目录权限设置涉及命令：chmod, chown chmod 命令是设置文件或应用的读写和可执行权限的，chown 是用来设置文件或应用的所有者的。具体关系为，不同用户针对不同的文件，拥有以下几种情况：1、所有者 User ：文件所属的用户。2、所有组 Group ：文件所属的用户组。3、Other 除了所有者和所有组之外。4、All 全部的用户。而针对不同的情况，可以设置不同的读写权限，例如：文件所有者可以读写和执行文件，其他用户或群组不可对该文件进行任何读写或执行。 一般情况下我们会将项目统一部署在一个根目录文件夹内，例如 /home/project 。因此，我们可以用 chown 命令对该文件夹设置所属用户组为管理用户组（admin），然后对 project 目录下的不同项目设置不同的所有者。最后，通过 chmod 对不同目录设置不同的读写执行权限来进行限制。同时，由于根目录下的所有文件夹默认是只有 root 用户可以进行写操作的，因此可以完美的限制运维管理账户的管理范围。 具体使用方法点击设计命令查看文档即可 4. Sudoer 配置涉及命令：sudo, visudo sudo 命令是Unix/Linux平台上的一个非常有用的工具，允许为非 root 用户赋予一些合理的”权限”，让他们执行一些只有根用户或特许用户才能完成的任务，从而减少根用户的登陆次数和管理时间同时也提高了系统安全性。 visudo 命令则是用于编辑 /etc/sudoer 配置文件的，该文件主要描述了哪些用户或用户组可以使用 sudo 命令来执行什么命令。/etc/sudoer 配置文件本身是可以通过 vim 等工具进行编辑的，使用 visudo 的主要用途是：可以避免多个管理员同时进行修改，然后提供一些简单的语法检查。 5. Iptables 防火墙涉及命令：iptables 防火墙主要配置一些敏感服务的对外访问，例如 Docker Daemon Remote API、Redis 等等。类似这些不需要公开到外网的服务，应在 iptables 上做好访问限制。其次，由于 Linux 系统中 1024 以下的端口均为系统保留端口，所以当启用需要占用 80 端口的 Nginx、Apache 时会被提示没有权限。如果不想给运维管理人员 sudo 权限的话，可以考虑将 Nginx 的端口绑定到大于 1024 的端口号上，然后通过 iptables 的 NAT 表进行转发。 参考文章： https://blog.csdn.net/sethcss/article/details/73395617 http://blog.51cto.com/wt7315/2051136 6. 应用服务安全 参考文章： 常见的 PHP 安全防范 Nginx 基本安全优化","categories":[{"name":"运维","slug":"运维","permalink":"https://saekiraku.github.io/categories/运维/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://saekiraku.github.io/tags/Linux/"},{"name":"安全","slug":"安全","permalink":"https://saekiraku.github.io/tags/安全/"}]},{"title":"基于 Ansible 的分布式爬虫自动化部署","slug":"基于Ansible的分布式爬虫自动化部署","date":"2018-06-14T07:24:10.000Z","updated":"2018-07-11T08:17:13.732Z","comments":true,"path":"article/23722/","link":"","permalink":"https://saekiraku.github.io/article/23722/","excerpt":"使用 NodeJS + Redis + Ansible 实现分布式爬虫并且自动化批量部署上线。","text":"使用 NodeJS + Redis + Ansible 实现分布式爬虫并且自动化批量部署上线。 本文章基于以下CC协议进行知识共享：署名（BY）-非商业性使用（NC）-禁止演绎（ND） 分布式爬虫之前在爬取一个网站的数据时，为了保证可以稳定的访问站点，不被网站屏蔽。尝试了很多方法，除了伪造请求头的UA、Cookie，还要对请求频率进行限制，或者通过代理服务器访问来改变请求来源。但是限制频率和请求代理会导致爬虫的效率变得非常低。因此，决定改成分布式爬虫，由多台服务器同时进行爬取。 该爬虫主要使用了 NodeJS 开发，并使用了 Cheerio 和 ioredis 两个框架。使用 Redis 同步各个爬虫的工作进度，并存储主要数据。 使用分布式爬虫，就需要为每个服务器安装环境，初始化配置等等。2、3个服务器还好说，但是如果有100台服务器，我们肯定不能手动的为每台服务器都配置一遍，1是人工容易出错，2是效率太低。 Ansible 自动化运维工具 基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。 除了 Ansible 以外，还有一款运维工具也是做服务器批量管理的 —— SaltStack。但是它的文档不够友好，并且由于通信机制的原因，需要在所有服务器上初始化一次 Salt Stack Minion，故没有选择此方案。（虽然 SaltStack 在后来也加入了 ssh 连接的支持） 安装 Ansible在官方文档中有很多安装方法，但是在这里我选择了使用 pip 进行安装（懒，图省事）。1pip install ansible 注意：使用 Ansible 时，进行管理的宿主机，必须是 Linux/MacOS/Unix 系统。 服务器与分组在很多教程中，对 Ansible 的服务器配置都是要修改 /etc/ansible/hosts 文件来实现的，但是通过 pip 安装是不会产生这个文件的。 当然我们可以手动去创建，但是尝试在终端中输入 ansible --help 就可以在帮助手册中看到能通过 -i 参数来指定 inventory 文件。 inventory 文件的格式简单的说就是用 [] 表示分组，用于批量管理，然后在分组下面写上服务器IP就可以了。IP后面写连接配置，例如一个服务器的登录用户名是root，密码是123456的配置写法是： 12[master] # 分组名称127.0.0.1 ansible_ssh_user=root ansible_ssh_pass=123456 注意：这种在配置中记录密码的方式并不安全，所以不推荐。最好是使用SSH密钥。 这个时候，我们就可以执行一些简单的命令，来测试配置是否正确了。在终端中输入 ansible master -i ./inventory -m ping 当你得到如下图所示的输出时，就算配置正确了。 最后，我们来分析一下真实的情况来写一个实际可用的配置。在这套爬虫系统中，除了每个服务器运行1个爬虫以外，还要有个服务器运行 redis 服务作为信息中枢。所以：所有服务器环境配置相同，单独拿出其中一个服务器再安装一个 redis 服务就可以了。同时，服务器连接使用 SSH 密钥的方式，最终配置如下。 12345678910[master]0.0.0.0 ansible_ssh_private_key_file=./private.pem[default]0.0.0.0 ansible_ssh_private_key_file=./private.pem0.0.0.0 ansible_ssh_private_key_file=./private.pem0.0.0.0 ansible_ssh_private_key_file=./private.pem0.0.0.0 ansible_ssh_private_key_file=./private.pem......# 配置中省略了服务器真实IP和数量 编写 playbook.ymlplaybook.yml 是 Ansible 的主要配置文件，通过它我们可以安装环境、执行脚本、编排任务等等。我们先以一个最简单的例子上手 —— 安装 Python 运行环境（假定你的服务器是 CentOS 系统，使用 yum 软件包管理器）。 1234567891011121314151617---- hosts: default # 服务器组 remote_user: root # 登录服务器用的用户名 sudo: yes # 是否使用 sudo 执行命令 tasks: # 任务列表 - name: 安装 python 环境 # 任务名称 yum: # 任务模块 name: python # yum 模块中的 name 参数（安装的软件包） state: installed # yum 模块中的 state 参数（要达到的状态） 然后我们在终端中输入 ansible-playbook -i ./inventory playbook.yml -f 10（-f 的数值是启动的进程数），就可以完美的跑起来这个脚本了。最后我们手动连入服务器，运行 python --version 来检查是否安装成功。（PS：在部分系统镜像中，python可能已经内置了） 在之前的简介中我们也说过 Ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。 所以，如果我们想通过 yum 安装软件包，那么就用 yum 模块；如果我们想管理 docker 容器，那么就用 docker_container 模块。当然，服务软件那么多，Ansible 的模块肯定不能做到完全覆盖。因此，我们还可以通过 command 模块写自定义命令来实现上述功能。 1234567---- hosts: default remote_user: root sudo: yes tasks: - name: 安装 python 环境 command: yum install -y python 那么这两种模式有什么区别？实际上我们观察 yum 模块的 state 的参数就会发现，他的值写的是 install 的过去式 installed 。这就表示 Ansible 追求的是任务达到了某个状态，而不是去做某个动作。这样做实际上是为了实现幂等性，也就是不管我们重复多少次操作，该操作的最终结果应该是一致的。 举个例子，假设 yum 包管理器不会为我们自动跳过已经安装的软件包，那么我们每执行一次这个配置，都会重复安装一遍 python，最后就会导致硬盘容量越来越小，浪费了很多空间。所以，在多数情况下，我们应该尽可能的使用 Ansible 的模块来保证幂等性。 最后，根据我的项目的实际情况，写出如下的 playbook 配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970---- hosts: default remote_user: root sudo: yes tasks: - name: 安装 python 环境 yum: name: python state: installed - name: 安装 git 版本管理工具 yum: name: git state: installed - name: 安装 Docker 环境（yum-utils） yum: name: yum-utils state: installed - name: 安装 Docker 环境（device-mapper-persistent-data） yum: name: device-mapper-persistent-data state: installed - name: 安装 Docker 环境（lvm2） yum: name: lvm2 state: installed - name: 安装 Docker 环境（add repo） yum_repository: name: docker-ce description: Docker CE Stable baseurl: https://download.docker.com/linux/centos/7/$basearch/stable gpgkey: https://download.docker.com/linux/centos/gpg gpgcheck: yes - name: 安装 Docker 环境（docker-ce） yum: name: docker-ce state: installed enablerepo: docker-ce - name: 启动 Docker systemd: name: docker state: started enabled: - name: 安装 docker-py pip: name: docker-py - name: 下拉 nodejs 镜像 docker_image: name: \"node:9.11-alpine\"- hosts: master remote_user: root tasks: - name: 下拉 redis 镜像 docker_image: name: \"redis:3.2-alpine\" - name: 启动 redis docker_container: name: redis image: \"redis:3.2-alpine\" restart_policy: always ports: - \"6379:6379\" volumes: - /app/data/redis:/data env: appendonly: yes state: started# 配置中省略了 NodeJS 容器的安装、运行等操作，因为大体的配置基本一样。更多操作直接参考官方文档即可。 最后，我们在终端中输入 ansible-playbook -i ./inventory playbook.yml -f 10，就可以自动化的初始化系统环境，并运行相应服务了。","categories":[{"name":"运维","slug":"运维","permalink":"https://saekiraku.github.io/categories/运维/"}],"tags":[]},{"title":"学习理论与产品化：知识体系","slug":"学习理论与产品化：知识体系","date":"2018-05-22T23:58:08.000Z","updated":"2018-08-03T08:00:49.349Z","comments":true,"path":"article/35563/","link":"","permalink":"https://saekiraku.github.io/article/35563/","excerpt":"以学习理论为基础，更科学、更可靠的设计产品。","text":"以学习理论为基础，更科学、更可靠的设计产品。 本文章保留所有版权，禁止转载 为何要考虑学习理论 关于三大学习理论的定义与理解：https://zhidao.baidu.com/question/279624894.html 在之前的关于 启嘉网/师导课/知识体系 的产品讨论中，我们一直为知识体系到底是以目标结果为节点进行展现，还是以知识点为节点进行展现的问题而无法确定产品设计的最终结果。在当时的产品讨论中，我们是以需求、交互、体验为基础进行讨论的。比如以目标为节点是更方便用户检索以项目化教学为基础的课程内容，以知识点为节点则更符合学生梳理、整理知识的习惯，更准确的形成系统化的知识体系。 但是我们都忽略了用户本身需要什么，用户为什么要学习？学习的动机是什么？会被那些因素刺激、影响？等等。为了搞清楚这些问题就需要有理论性的东西来支撑了，意义就是当我们搞清楚学习的动机、内因、外因、刺激源等问题时，自然就可以知道应该以什么方式来展现知识体系了。 课程设计与行为主义理论目前来看，我们的课程设计主要是基于行为主义理论的。比如我们设计了项目化教学的课程，其本质意义是为了得到“提高学生实际项目开发经验”的结果。而每几周一个项目的课时目标，实际上是一种不断的强化。那么刺激源是什么？虽然我们没有刻意的去运营刺激源，但是在往期的项目验收中，我们的学生普遍说的是成就感。 因此，我们其实可以认为以目标为节点的知识体系是比较贴近行为主义理论的。通过对目标、结果的梳理，方便学生快速定位知识点。 知识体系与建构主义理论那么相对的，以知识点为节点的知识体系贴近的就是建构主义理论了。知识点节点的意义在于，拥有一个完整且规范的知识体系图谱，辅助了学生构建知识与经验的认知。 建构主义理论强调学生在学习过程中主动建构知识的意义，并力图在更接近、更符合实际情况的情境性学习活动中，以个人原有的经验、心理结构和信念为基础来建构和理解新知识。建构是对新知识意义的建构，同时又包含对原有经验的改造和重组。 反思通过对学习理论的理解，然后结合实际情况的分析，我总结了如下几点： 课程设计上，我们是否可以考虑融入一些认知主义理论的内容？如兴趣引导等。 在学习的初期，行为主义理论的作用是否更大？ 根据建构主义理论，产品本身的意义是否不是呈现一个知识体系，而是辅助学生去构建知识体系？ 总结综上所述，我的看法是：可能在学习初期，学生是没有必要去看一个完整的知识体系的，因为知识水平和经验有限，兴趣又没有带动起来，是没有总结知识体系的能力的。所以在这个时期，我觉得重要的是通过什么方法和手段可以刺激学生、保证学生的学习动力。例如通过目标节点的知识体系快速找到所需要的内容，来高效率的完成作业，以保证“成就感”。 当一个学习阶段结束后，学生根据自己的项目经验，反过来看以知识点为节点所展现的知识体系。这个时候，产品、老师对学生起到一个辅助的作用，帮助学生完成知识体系的建构。也就是所谓的建构主义理论。但是在这其中，产品不必起到关联目标与知识点的作用，因为这部分应该是学生自我构建认知的过程。 THE END, THANKS FOR READ.","categories":[{"name":"产品","slug":"产品","permalink":"https://saekiraku.github.io/categories/产品/"}],"tags":[]},{"title":"Webpack 前端编译策略优化","slug":"Webpack-前端编译策略优化","date":"2018-05-17T06:01:55.000Z","updated":"2018-07-11T08:08:58.710Z","comments":true,"path":"article/26242/","link":"","permalink":"https://saekiraku.github.io/article/26242/","excerpt":"在前端工程化盛行的今天，很多公司为了提升开发效率与项目可维护性，都开始使用上了webpack这样的自动化工具。在享受自动化高效率的同时，也产生了一些性能上的问题：代码重复引用、臃肿的混合JS库、编译速度慢……，很多技术人员面对此类问题无从下手，求助于百度但是却不求甚解。所以本文将通过我工作中实际遇到的问题进行分析、解释原因、并给出解决方案的几个步骤，来讲解前端自动化中的优化问题。","text":"在前端工程化盛行的今天，很多公司为了提升开发效率与项目可维护性，都开始使用上了webpack这样的自动化工具。在享受自动化高效率的同时，也产生了一些性能上的问题：代码重复引用、臃肿的混合JS库、编译速度慢……，很多技术人员面对此类问题无从下手，求助于百度但是却不求甚解。所以本文将通过我工作中实际遇到的问题进行分析、解释原因、并给出解决方案的几个步骤，来讲解前端自动化中的优化问题。 本文章基于以下CC协议进行知识共享：署名（BY）-非商业性使用（NC）-禁止演绎（ND） 注意： 本文假设您已有webpack基础，并了解基本的配置项的意义。适用于在此基础上希望能了解一些 webpack 的优化规则的情况。 本文不会详细到具体的实施代码，仅提供思路，具体操作请查阅webpack文档。 问题1：编译后文件体积过大该问题是指执行编译后，webpack在控制台输出的数据中的资源体积过大。一般会用黄色的字体标注上[big]。有时编译策略的错误，会导致代码文件达到5、6MB甚至10MB以上。假设用户的网速是2MB/s，加载一次页面也需要3s，并且再考虑到服务器的出口带宽，可能就需要数十秒才能显示出页面。 但是，文件体积过大又分很多种情况，所以要具体情况具体分析。我们先从最简单的开始说。 CSS文件过大一般CSS文件不会过大，而且也没什么可优化的，毕竟CSS只是描述样式，没有逻辑，所以不会像JS出现重复引用的问题。只需要确保 LoaderOptionsPlugin 下开启了 minimize 。打包后的CSS就会自动去除不必要的换行符和空格等。 JS文件过大JS 文件过大的情况处理起来就比较复杂了，因为有很多可能性会导致JS文件过大。为了不盲目的解决问题，我们需要使用 webpack-bundle-analyzer 这个工具来分析具体是什么原因导致的问题。 重复引用重复引用是一个非常常见的问题，虽然很多 webpack 脚手架都自带了 CommonsChunkPlugin 的配置 —— 将重复引用的JS模块打包进一个总的混合JS包中(常见命名：Common.js / Vendor.js / Lib.js……)，这样做的好处是降低页面加载时的并发量。参见：加载缓慢/HTTP并发 但是偶尔的，在某些特定情况下 CommonsChunkPlugin 会没起到作用。我们使用 webpack-bundle-analyzer 分析一下编译后的代码引用结构。 仔细观察上图，我们就会发现所有被按需加载的页面，都反复加载了 Ant.Design 组件库中使用到的组件。假如每个页面都用到了 Button 组件，那么当用户浏览网页中的其他内容时， Button 组件将会反复的被加载，白白浪费了网络带宽。 这个问题是因为项目按照 Ant.Design 官方文档的配置，增加了组件库的按需加载。因此使整个组件库独立出 CommonsChunkPlugin 的策略外了。 所以针对这个特殊情况，我们其实应该将 Ant.Design 从代码中抽离出来，然后使用 CDN 加载。虽然一次性的加载了一个非常大的类库，但是进入缓存后，后面的加载就会非常快了。同时，由于是后台系统，基本上一个页面中能用到的组件都用到了，使用按需加载会反复加载N次很多相同的组件代码。两者相比较起来，按需加载实际上就没有意义了。 第三方类库第三方类库一般是引起 Vendor.js 这样的文件过大的主要原因，实际上除非特殊需要，我们没有必要将第三方类库打包进我们的项目中。一般都是通过一些第三方的CDN服务(如：BootCDN)来引入类库，1是能减少网站自身的流量使用，2是用户访问过其他网站，并且那个网站使用了同一个CDN地址时，就会直接命中缓存，而不用重新加载，减少了用户的等待时间。 webpack版本过低这个问题目前（2018-05-17）应该不会有了，毕竟都已经webpack 4了。这里主要是想提一句 webpack 2 时增加的 Tree Shaking 代码优化技术。在一些公司的面试中可能会有考核，更多的内容，自己百度一下把。 按需加载参见：加载缓慢/按需加载 问题2：加载缓慢加载缓慢是指用户用户访问网站后长时间无法显示主要内容和页面。当我们通过问题1尽可能的缩减文件体积后，如果加载依然缓慢，就要考虑从服务器方面进行优化了。 加载请求并发假设我们一个页面引用了 10 余个JS模块，当加载这些JS文件时，HTTP协议会进行3次握手4次挥手，相当于加载完整个页面，就与服务器进行了70余次的连接/断开通信，大部分时间就都浪费在了建立连接的网络通信上。因此我们使用 CommonsChunkPlugin 将各个页面都会用到的模块打包进一个综合的Vendor.js中。来降低多次建立连接与并发。 启用缓存通过上面的步骤尽可能的优化代码体积后，下一步要做的就是开启缓存。如果不开启缓存的话，用户每一次打开网站，都会从服务器重复的加载相同的资源文件。这样显然也是白白浪费带宽了。 但是开启缓存后，如果我们更新了网站代码，浏览器会由于缓存原因，无法立刻同步最新代码。因此，我们需要使用 webpack 的 hash 标签来为资源文件进行命名。这样每一次编译的时候，资源文件都会被命名为类似 xxxx.fea39cda7bxxxx.js ，并且当文件内容发生变化后，hash 值也会发生变化，这样就会导致浏览器重新加载这个文件。也就达到了更新版本的目的了。 但是别忘了不要给html加缓存，否则HTML上的JS引用地址由于缓存也会无法更新了。以Nginx为例的配置： 123456789location ~ html$ &#123; ... add_header Cache-Control no-store;&#125;location ~ (js|css|png|jpg)$ &#123; ... expires 30d;&#125; 按需加载按需加载实际上是一个与业务逻辑相关的优化方案，比如对于SPA应用，使用前端路由进行页面跳转，用按需加载进行优化就很合理了。通常会以页面为单位，进行代码分隔，然后访问到哪个路由时再单独加载。这样将不需要一次性加载完的代码分隔出去，就可以有效的减少单个的代码文件的体积。 按需加载的实现请参考 webpack 文档：require.ensure 问题3：编译缓慢编译缓慢是指webpack在开发环境和生产环境，代码热更新慢、编译速度慢等问题。 使用 CommonsChunkPlugin 整合第三方类库关于这个插件前面已经讲过很多了，这里主要说一下为什么使用 CommonsChunkPlugin 可以提升编译速度。主要是因为如果不整合第三方类库，每一次编译webpack都会重新处理页面中模块的引用关系，而特别大的类库也会重新加载编译。通过启用 CommonsChunkPlugin 将类库代码整合后再配合 DllPlugin &amp; DllReferencePlugin 就可以极大的提高编译效率。 使用 DllPlugin &amp; DllReferencePlugin 对第三方类库进行预编译一般情况下我们会将第三方类库抽离出去，并通过 CDN 加载。但是如果是我们自己开发的类库、或者没有服务商托管该第三方类库的 CDN 链接的情况下，就只能编译进 Vendor.js 中。通常情况下类库是基本不会有代码变动的，但是 webpack 每次编译依然会重新处理这些类库，这样就导致重复做了很多工作，编译效率自然就低了。通过 DllPlugin &amp; DllReferencePlugin 允许我们将不常变动的大类库预先处理，然后在需要的时候直接引用预编译的结果。一般情况下该方法能带来10~20s的速度提升。 开发环境下关闭不必要的Plugins在开发环境时可以关闭uglifyjs-webpack-plugin、extract-text-webpack-plugin等插件。因为在开发环境下调试，没有必要对JS进行压缩或对CSS进行提取，同时这些插件会非常影响编译效率。但是有一点要注意的是，关闭extract-text-webpack-plugin后，开发环境下的页面的CSS将由JS进行填充，因此会导致页面刷新时有几百毫秒的样式丢失。同时类似Vue的v-clock也将失效。要注意区分，不要误以为是BUG。 另外 hash 也是一个影响编译效率的东西，因为需要计算文件的哈希值。 关闭 source-map 源映射source-map 是一个能让开发者工具在编译后的代码中迅速找到对应的源代码的位置的功能，可以很方便的追踪到控制台的报错。但是，源映射本身非常影响编译效率，而在生产环境中，我们其实没有必要在线上追踪调试错误。毕竟你不能每时每刻的都在用户旁边盯着控制台报错然后点进去。最终我们都是从用户那里收集反馈，然后在开发环境下重现BUG。因此，生产环境的source-map是没必要开启的。 当然，如果你特别强烈的想在生产环境开启 source-map，那么可以参考一下webpack文档中source-map的几种方式，然后综合考虑一下（速度、功能）选择一个最适合你的方案。 使用 HappyPack 多线程编译这个不必多说，由于webpack是跑在NodeJS下的，而NodeJS又是单线程，无法充分利用多核CPU的优势。使用 HappyPack 就可以解决这个问题，从而提升编译效率。具体实施请自行查看文档。 使用内存编译webpack Node API 在编译时可以提供一个基于fs模块接口的文件系统，相比于直接对硬盘读写，使用 memory-fs 在内存中进行读写效率会高很多。","categories":[{"name":"前端","slug":"前端","permalink":"https://saekiraku.github.io/categories/前端/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"https://saekiraku.github.io/tags/webpack/"}]}]}